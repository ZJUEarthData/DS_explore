********************************************** 
 
Version: Python 3.7.6 
IDE: Jupyter Notebook
@author: 何灿 Sany
Time: 2020/08/07
Email: sanyhew1097618435@163.com
Related Video:
（一）https://www.youtube.com/watch?v=tvmkhTwlhe8&list=PLy8hNsI55lviQ9sYJ2TbuNKV9nduzx7Rh&index=2
（二）https://www.youtube.com/watch?v=l8t3RLrw8O4&list=PLy8hNsI55lviQ9sYJ2TbuNKV9nduzx7Rh
**********************************************

Package:
numpy、pandas、matplolib、sklearn、os、xgboost

Realization (demo: classification algorithm):
1. Implement common ensemble learning models: Voting Classifier, Bagging and Pasting, Random Forest, Adaboost, GradientBoosting (including xgboost), Stacking Ensemble
2. Feature importance and visualization: Random Forest, Adaboost, GradientBoosting (xgboost)
3. Two-dimensional visualized single classifier and ensemble learning model

Dataset:
【data.xlsx】：The TRUE VALUE column in the data set is the actual category information

Further work that needs to be done:
Deploy the integrated learning algorithm on the existing framework and explore each integrated algorithm in depth

Note:
1. This is just a rough version of exploration and application of the ensemble learning algorithm. The classifier with the optimal parameters can be put into the ensemble learning model
2. Ensemble learning can be used in regression or classification models. Customized code blocks can be used. Here is only classification demo and regression demo will be implemented after then
3. Hyperparameter tuning can be refered to official documents. The hyperparameters of ensemble learning based on the tree model are mostly the same. Here we only explore the hyperparameters that are obviously different in various ensemble learning models.
4. 【learning_images】, 【data.xlsx】, 【ensemble_learning.ipynb】need to be placed in the same working directory

*********************************************

